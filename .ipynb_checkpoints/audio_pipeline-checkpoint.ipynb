{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "folder_path = \"SpeechAO_AllActors/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import subprocess\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_wav_file_paths(folder_path):\n",
    "    return list(map(lambda a: folder_path + str(a), \n",
    "               filter(lambda a: \".wav\" in str(a), subprocess.check_output(['ls', folder_path]).splitlines())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, aubio\n",
    "import sys\n",
    "from aubio import source, pvoc, mfcc\n",
    "from numpy import vstack, zeros, diff\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def process_wav_file(filename,\n",
    "                     samplerate = 0,\n",
    "                     win_s = 1024,\n",
    "                     seconds_window = 3,\n",
    "                     svm = True):\n",
    "    hop_s = win_s // 4\n",
    "    filename = filename.replace(\"b'\", \"\")[:-1]\n",
    "    #print(filename)\n",
    "    n_filters = 40              # must be 40 for mfcc\n",
    "    n_coeffs = 13\n",
    "    s = source(filename, samplerate, hop_s)\n",
    "    p = pvoc(win_s, hop_s)\n",
    "    m = mfcc(win_s, n_filters, n_coeffs, samplerate)\n",
    "    n_samples = 1#s.duration / s.samplerate / seconds_window\n",
    "    if n_samples == 0:\n",
    "        return []\n",
    "    mfccs = zeros([n_coeffs,])\n",
    "    frames_read = 0\n",
    "    while True:\n",
    "        samples, read = s()\n",
    "        #print(samples, read)\n",
    "        spec = p(samples)\n",
    "        mfcc_out = m(spec)\n",
    "        mfccs = vstack((mfccs, mfcc_out))\n",
    "        frames_read += read\n",
    "        if read < hop_s: break\n",
    "\n",
    "    mfccs1 = diff(mfccs, axis = 0)\n",
    "    mfccs2 = diff(mfccs, axis = 0)\n",
    "    #print mfccs.shape, mfccs1.shape, mfccs2.shape\n",
    "    all_data = np.concatenate((mfccs[1:,:], mfccs1, mfccs1), 1)\n",
    "    \n",
    "    final = []\n",
    "    size_row = len(all_data) / n_samples\n",
    "    if svm:\n",
    "        final.append(get_mean_avg_etc(all_data))\n",
    "    else:    \n",
    "        final.append(all_data)\n",
    "#     for i in range(n_samples):\n",
    "#         if svm:\n",
    "#             final.append(get_mean_avg_etc(all_data[i*size_row: (i+1)*size_row]))\n",
    "#         else:    \n",
    "#             final.append(all_data[i*size_row: (i+1)*size_row])\n",
    "    return final\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Speech (1 = neutral, 2 = calm, 3 = happy, 4 = sad, 5 = angry, 6 = fearful, 7 = disgust, 8 = surprised)\n",
    "\n",
    "def get_label(filename, svm):\n",
    "    row = np.zeros(8)\n",
    "    filename = filename.split(\"-\")\n",
    "    row[int(filename[2]) - 1] = 1\n",
    "    if svm:\n",
    "        return int(filename[2]) - 1\n",
    "    else:\n",
    "        return row\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_mean_avg_etc(row):\n",
    "    new_row = []\n",
    "    new_row += list(row.mean(axis = 0))\n",
    "    new_row += list(row.std(axis = 0))\n",
    "    new_row += list(row.min(axis = 0))\n",
    "    new_row += list(row.max(axis = 0))\n",
    "    return new_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random \n",
    "def make_dataset(folder_path, svm = True):\n",
    "    filenames = get_wav_file_paths(folder_path)\n",
    "    np.random.shuffle(filenames)\n",
    "    y = []\n",
    "    X = []\n",
    "    for filename in filenames:\n",
    "        tmp_x = process_wav_file(filename, svm = svm)\n",
    "        n = len(tmp_x)\n",
    "        if svm:\n",
    "            tmp_y = [get_label(filename, svm), ]*n\n",
    "        else:\n",
    "            tmp_y = [list(get_label(filename, svm)), ]*n\n",
    "\n",
    "\n",
    "        X += tmp_x\n",
    "        y += tmp_y\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = make_dataset(folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1440, 156), (1440,))"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sklearn.preprocessing\n",
    "#X = sklearn.preprocessing.normalize(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### CLF 1 - SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/gensim/utils.py:1015: UserWarning: Pattern library is not installed, lemmatization won't be available.\n",
      "  warnings.warn(\"Pattern library is not installed, lemmatization won't be available.\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/scipy/sparse/sparsetools.py:20: DeprecationWarning: `scipy.sparse.sparsetools` is deprecated!\n",
      "scipy.sparse.sparsetools is a private module for scipy.sparse, and should not be used.\n",
      "  _deprecated()\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "import sklearn, sklearn.datasets\n",
    "import sklearn.naive_bayes, sklearn.linear_model, sklearn.svm, sklearn.neighbors, sklearn.ensemble\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.sparse\n",
    "import numpy as np\n",
    "import time, re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def baseline(train_data, train_labels, test_data, test_labels, omit=[]):\n",
    "    \"\"\"Train various classifiers to get a baseline.\"\"\"\n",
    "    clf, train_accuracy, test_accuracy, train_f1, test_f1, exec_time = [], [], [], [], [], []\n",
    "    #clf.append(sklearn.neighbors.KNeighborsClassifier(n_neighbors=10))\n",
    "    #clf.append(sklearn.ensemble.AdaBoostClassifier())\n",
    "    #clf.append(sklearn.naive_bayes.BernoulliNB(alpha=.01))\n",
    "    clf.append(sklearn.ensemble.RandomForestClassifier(n_estimators=100, max_depth=5))\n",
    "    #clf.append(sklearn.naive_bayes.MultinomialNB(alpha=.01))\n",
    "    clf.append(sklearn.ensemble.GradientBoostingClassifier(max_depth=5))\n",
    "    #clf.append(sklearn.svm.SVC())\n",
    "    clf.append(sklearn.linear_model.RidgeClassifier())\n",
    "    #clf.append(sklearn.svm.LinearSVC())\n",
    "    for i,c in enumerate(clf):\n",
    "        if i not in omit:\n",
    "            print(c)\n",
    "            #t_start = time.process_time()\n",
    "            c.fit(train_data, train_labels)\n",
    "            train_pred = c.predict(train_data)\n",
    "            test_pred = c.predict(test_data)\n",
    "            train_accuracy.append('{:5.2f}'.format(100*sklearn.metrics.accuracy_score(train_labels, train_pred)))\n",
    "            test_accuracy.append('{:5.2f}'.format(100*sklearn.metrics.accuracy_score(test_labels, test_pred)))\n",
    "            train_f1.append('{:5.2f}'.format(100*sklearn.metrics.f1_score(train_labels, train_pred, average='weighted')))\n",
    "            test_f1.append('{:5.2f}'.format(100*sklearn.metrics.f1_score(test_labels, test_pred, average='weighted')))\n",
    "            #exec_time.append('{:5.2f}'.format(time.process_time() - t_start))\n",
    "    print('Train accuracy:      {}'.format(' '.join(train_accuracy)))\n",
    "    print('Test accuracy:       {}'.format(' '.join(test_accuracy)))\n",
    "    print('Train F1 (weighted): {}'.format(' '.join(train_f1)))\n",
    "    print('Test F1 (weighted):  {}'.format(' '.join(test_f1)))\n",
    "    #print('Execution time:      {}'.format(' '.join(exec_time)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "limit = int(X.shape[0] / 10 * 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X[:limit]\n",
    "y_train = y[:limit]\n",
    "X_val = X[limit:]\n",
    "y_val = y[limit:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-merror:0.173611\ttest-merror:0.673611\n",
      "[1]\ttrain-merror:0.126736\ttest-merror:0.635417\n",
      "[2]\ttrain-merror:0.092014\ttest-merror:0.635417\n",
      "[3]\ttrain-merror:0.08941\ttest-merror:0.614583\n",
      "[4]\ttrain-merror:0.06684\ttest-merror:0.607639\n",
      "[5]\ttrain-merror:0.054688\ttest-merror:0.618056\n",
      "[6]\ttrain-merror:0.049479\ttest-merror:0.59375\n",
      "[7]\ttrain-merror:0.038194\ttest-merror:0.586806\n",
      "[8]\ttrain-merror:0.032118\ttest-merror:0.590278\n",
      "[9]\ttrain-merror:0.02691\ttest-merror:0.59375\n",
      "[10]\ttrain-merror:0.023438\ttest-merror:0.583333\n",
      "[11]\ttrain-merror:0.017361\ttest-merror:0.583333\n",
      "[12]\ttrain-merror:0.015625\ttest-merror:0.576389\n",
      "[13]\ttrain-merror:0.013021\ttest-merror:0.576389\n",
      "[14]\ttrain-merror:0.012153\ttest-merror:0.572917\n",
      "[15]\ttrain-merror:0.007812\ttest-merror:0.5625\n",
      "[16]\ttrain-merror:0.006944\ttest-merror:0.565972\n",
      "[17]\ttrain-merror:0.005208\ttest-merror:0.5625\n",
      "[18]\ttrain-merror:0.005208\ttest-merror:0.555556\n",
      "[19]\ttrain-merror:0.005208\ttest-merror:0.552083\n",
      "[20]\ttrain-merror:0.002604\ttest-merror:0.548611\n",
      "[21]\ttrain-merror:0.001736\ttest-merror:0.534722\n",
      "[22]\ttrain-merror:0.000868\ttest-merror:0.541667\n",
      "[23]\ttrain-merror:0.000868\ttest-merror:0.541667\n",
      "[24]\ttrain-merror:0.000868\ttest-merror:0.541667\n",
      "[25]\ttrain-merror:0.000868\ttest-merror:0.538194\n",
      "[26]\ttrain-merror:0.000868\ttest-merror:0.541667\n",
      "[27]\ttrain-merror:0\ttest-merror:0.534722\n",
      "[28]\ttrain-merror:0\ttest-merror:0.53125\n",
      "[29]\ttrain-merror:0\ttest-merror:0.541667\n",
      "[30]\ttrain-merror:0\ttest-merror:0.524306\n",
      "[31]\ttrain-merror:0\ttest-merror:0.53125\n",
      "[32]\ttrain-merror:0\ttest-merror:0.527778\n",
      "[33]\ttrain-merror:0\ttest-merror:0.538194\n",
      "[34]\ttrain-merror:0\ttest-merror:0.534722\n",
      "[35]\ttrain-merror:0\ttest-merror:0.534722\n",
      "[36]\ttrain-merror:0\ttest-merror:0.538194\n",
      "[37]\ttrain-merror:0\ttest-merror:0.53125\n",
      "[38]\ttrain-merror:0\ttest-merror:0.53125\n",
      "[39]\ttrain-merror:0\ttest-merror:0.53125\n",
      "[40]\ttrain-merror:0\ttest-merror:0.53125\n",
      "[41]\ttrain-merror:0\ttest-merror:0.527778\n",
      "[42]\ttrain-merror:0\ttest-merror:0.517361\n",
      "[43]\ttrain-merror:0\ttest-merror:0.524306\n",
      "[44]\ttrain-merror:0\ttest-merror:0.517361\n",
      "[45]\ttrain-merror:0\ttest-merror:0.53125\n",
      "[46]\ttrain-merror:0\ttest-merror:0.53125\n",
      "[47]\ttrain-merror:0\ttest-merror:0.520833\n",
      "[48]\ttrain-merror:0\ttest-merror:0.520833\n",
      "[49]\ttrain-merror:0\ttest-merror:0.517361\n",
      "[50]\ttrain-merror:0\ttest-merror:0.520833\n",
      "[51]\ttrain-merror:0\ttest-merror:0.510417\n",
      "[52]\ttrain-merror:0\ttest-merror:0.506944\n",
      "[53]\ttrain-merror:0\ttest-merror:0.510417\n",
      "[54]\ttrain-merror:0\ttest-merror:0.506944\n",
      "[55]\ttrain-merror:0\ttest-merror:0.510417\n",
      "[56]\ttrain-merror:0\ttest-merror:0.510417\n",
      "[57]\ttrain-merror:0\ttest-merror:0.513889\n",
      "[58]\ttrain-merror:0\ttest-merror:0.510417\n",
      "[59]\ttrain-merror:0\ttest-merror:0.513889\n",
      "[60]\ttrain-merror:0\ttest-merror:0.510417\n",
      "[61]\ttrain-merror:0\ttest-merror:0.506944\n",
      "[62]\ttrain-merror:0\ttest-merror:0.510417\n",
      "[63]\ttrain-merror:0\ttest-merror:0.513889\n",
      "[64]\ttrain-merror:0\ttest-merror:0.510417\n",
      "[65]\ttrain-merror:0\ttest-merror:0.513889\n",
      "[66]\ttrain-merror:0\ttest-merror:0.506944\n",
      "[67]\ttrain-merror:0\ttest-merror:0.506944\n",
      "[68]\ttrain-merror:0\ttest-merror:0.503472\n",
      "[69]\ttrain-merror:0\ttest-merror:0.503472\n",
      "[70]\ttrain-merror:0\ttest-merror:0.503472\n",
      "[71]\ttrain-merror:0\ttest-merror:0.503472\n",
      "[72]\ttrain-merror:0\ttest-merror:0.503472\n",
      "[73]\ttrain-merror:0\ttest-merror:0.503472\n",
      "[74]\ttrain-merror:0\ttest-merror:0.506944\n",
      "[75]\ttrain-merror:0\ttest-merror:0.506944\n",
      "[76]\ttrain-merror:0\ttest-merror:0.510417\n",
      "[77]\ttrain-merror:0\ttest-merror:0.506944\n",
      "[78]\ttrain-merror:0\ttest-merror:0.506944\n",
      "[79]\ttrain-merror:0\ttest-merror:0.510417\n",
      "[80]\ttrain-merror:0\ttest-merror:0.510417\n",
      "[81]\ttrain-merror:0\ttest-merror:0.510417\n",
      "[82]\ttrain-merror:0\ttest-merror:0.510417\n",
      "[83]\ttrain-merror:0\ttest-merror:0.513889\n",
      "[84]\ttrain-merror:0\ttest-merror:0.513889\n",
      "[85]\ttrain-merror:0\ttest-merror:0.513889\n",
      "[86]\ttrain-merror:0\ttest-merror:0.513889\n",
      "[87]\ttrain-merror:0\ttest-merror:0.513889\n",
      "[88]\ttrain-merror:0\ttest-merror:0.510417\n",
      "[89]\ttrain-merror:0\ttest-merror:0.510417\n",
      "[90]\ttrain-merror:0\ttest-merror:0.510417\n",
      "[91]\ttrain-merror:0\ttest-merror:0.510417\n",
      "[92]\ttrain-merror:0\ttest-merror:0.510417\n",
      "[93]\ttrain-merror:0\ttest-merror:0.503472\n",
      "[94]\ttrain-merror:0\ttest-merror:0.506944\n",
      "[95]\ttrain-merror:0\ttest-merror:0.506944\n",
      "predicting, classification error=0.506944\n",
      "[0]\ttrain-merror:0.173611\ttest-merror:0.673611\n",
      "[1]\ttrain-merror:0.126736\ttest-merror:0.635417\n",
      "[2]\ttrain-merror:0.092014\ttest-merror:0.635417\n",
      "[3]\ttrain-merror:0.08941\ttest-merror:0.614583\n",
      "[4]\ttrain-merror:0.06684\ttest-merror:0.607639\n",
      "[5]\ttrain-merror:0.054688\ttest-merror:0.618056\n",
      "[6]\ttrain-merror:0.049479\ttest-merror:0.59375\n",
      "[7]\ttrain-merror:0.038194\ttest-merror:0.586806\n",
      "[8]\ttrain-merror:0.032118\ttest-merror:0.590278\n",
      "[9]\ttrain-merror:0.02691\ttest-merror:0.59375\n",
      "[10]\ttrain-merror:0.023438\ttest-merror:0.583333\n",
      "[11]\ttrain-merror:0.017361\ttest-merror:0.583333\n",
      "[12]\ttrain-merror:0.015625\ttest-merror:0.576389\n",
      "[13]\ttrain-merror:0.013021\ttest-merror:0.576389\n",
      "[14]\ttrain-merror:0.012153\ttest-merror:0.572917\n",
      "[15]\ttrain-merror:0.007812\ttest-merror:0.5625\n",
      "[16]\ttrain-merror:0.006944\ttest-merror:0.565972\n",
      "[17]\ttrain-merror:0.005208\ttest-merror:0.5625\n",
      "[18]\ttrain-merror:0.005208\ttest-merror:0.555556\n",
      "[19]\ttrain-merror:0.005208\ttest-merror:0.552083\n",
      "[20]\ttrain-merror:0.002604\ttest-merror:0.548611\n",
      "[21]\ttrain-merror:0.001736\ttest-merror:0.534722\n",
      "[22]\ttrain-merror:0.000868\ttest-merror:0.541667\n",
      "[23]\ttrain-merror:0.000868\ttest-merror:0.541667\n",
      "[24]\ttrain-merror:0.000868\ttest-merror:0.541667\n",
      "[25]\ttrain-merror:0.000868\ttest-merror:0.538194\n",
      "[26]\ttrain-merror:0.000868\ttest-merror:0.541667\n",
      "[27]\ttrain-merror:0\ttest-merror:0.534722\n",
      "[28]\ttrain-merror:0\ttest-merror:0.53125\n",
      "[29]\ttrain-merror:0\ttest-merror:0.541667\n",
      "[30]\ttrain-merror:0\ttest-merror:0.524306\n",
      "[31]\ttrain-merror:0\ttest-merror:0.53125\n",
      "[32]\ttrain-merror:0\ttest-merror:0.527778\n",
      "[33]\ttrain-merror:0\ttest-merror:0.538194\n",
      "[34]\ttrain-merror:0\ttest-merror:0.534722\n",
      "[35]\ttrain-merror:0\ttest-merror:0.534722\n",
      "[36]\ttrain-merror:0\ttest-merror:0.538194\n",
      "[37]\ttrain-merror:0\ttest-merror:0.53125\n",
      "[38]\ttrain-merror:0\ttest-merror:0.53125\n",
      "[39]\ttrain-merror:0\ttest-merror:0.53125\n",
      "[40]\ttrain-merror:0\ttest-merror:0.53125\n",
      "[41]\ttrain-merror:0\ttest-merror:0.527778\n",
      "[42]\ttrain-merror:0\ttest-merror:0.517361\n",
      "[43]\ttrain-merror:0\ttest-merror:0.524306\n",
      "[44]\ttrain-merror:0\ttest-merror:0.517361\n",
      "[45]\ttrain-merror:0\ttest-merror:0.53125\n",
      "[46]\ttrain-merror:0\ttest-merror:0.53125\n",
      "[47]\ttrain-merror:0\ttest-merror:0.520833\n",
      "[48]\ttrain-merror:0\ttest-merror:0.520833\n",
      "[49]\ttrain-merror:0\ttest-merror:0.517361\n",
      "[50]\ttrain-merror:0\ttest-merror:0.520833\n",
      "[51]\ttrain-merror:0\ttest-merror:0.510417\n",
      "[52]\ttrain-merror:0\ttest-merror:0.506944\n",
      "[53]\ttrain-merror:0\ttest-merror:0.510417\n",
      "[54]\ttrain-merror:0\ttest-merror:0.506944\n",
      "[55]\ttrain-merror:0\ttest-merror:0.510417\n",
      "[56]\ttrain-merror:0\ttest-merror:0.510417\n",
      "[57]\ttrain-merror:0\ttest-merror:0.513889\n",
      "[58]\ttrain-merror:0\ttest-merror:0.510417\n",
      "[59]\ttrain-merror:0\ttest-merror:0.513889\n",
      "[60]\ttrain-merror:0\ttest-merror:0.510417\n",
      "[61]\ttrain-merror:0\ttest-merror:0.506944\n",
      "[62]\ttrain-merror:0\ttest-merror:0.510417\n",
      "[63]\ttrain-merror:0\ttest-merror:0.513889\n",
      "[64]\ttrain-merror:0\ttest-merror:0.510417\n",
      "[65]\ttrain-merror:0\ttest-merror:0.513889\n",
      "[66]\ttrain-merror:0\ttest-merror:0.506944\n",
      "[67]\ttrain-merror:0\ttest-merror:0.506944\n",
      "[68]\ttrain-merror:0\ttest-merror:0.503472\n",
      "[69]\ttrain-merror:0\ttest-merror:0.503472\n",
      "[70]\ttrain-merror:0\ttest-merror:0.503472\n",
      "[71]\ttrain-merror:0\ttest-merror:0.503472\n",
      "[72]\ttrain-merror:0\ttest-merror:0.503472\n",
      "[73]\ttrain-merror:0\ttest-merror:0.503472\n",
      "[74]\ttrain-merror:0\ttest-merror:0.506944\n",
      "[75]\ttrain-merror:0\ttest-merror:0.506944\n",
      "[76]\ttrain-merror:0\ttest-merror:0.510417\n",
      "[77]\ttrain-merror:0\ttest-merror:0.506944\n",
      "[78]\ttrain-merror:0\ttest-merror:0.506944\n",
      "[79]\ttrain-merror:0\ttest-merror:0.510417\n",
      "[80]\ttrain-merror:0\ttest-merror:0.510417\n",
      "[81]\ttrain-merror:0\ttest-merror:0.510417\n",
      "[82]\ttrain-merror:0\ttest-merror:0.510417\n",
      "[83]\ttrain-merror:0\ttest-merror:0.513889\n",
      "[84]\ttrain-merror:0\ttest-merror:0.513889\n",
      "[85]\ttrain-merror:0\ttest-merror:0.513889\n",
      "[86]\ttrain-merror:0\ttest-merror:0.513889\n",
      "[87]\ttrain-merror:0\ttest-merror:0.513889\n",
      "[88]\ttrain-merror:0\ttest-merror:0.510417\n",
      "[89]\ttrain-merror:0\ttest-merror:0.510417\n",
      "[90]\ttrain-merror:0\ttest-merror:0.510417\n",
      "[91]\ttrain-merror:0\ttest-merror:0.510417\n",
      "[92]\ttrain-merror:0\ttest-merror:0.510417\n",
      "[93]\ttrain-merror:0\ttest-merror:0.503472\n",
      "[94]\ttrain-merror:0\ttest-merror:0.506944\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[95]\ttrain-merror:0\ttest-merror:0.506944\n",
      "predicting, classification error=0.506944\n"
     ]
    }
   ],
   "source": [
    "xg_train = xgb.DMatrix( X_train, label=y_train)\n",
    "xg_test = xgb.DMatrix(X_val, label=y_val)\n",
    "# setup parameters for xgboost\n",
    "param = {}\n",
    "# use softmax multi-class classification\n",
    "param['objective'] = 'multi:softmax'\n",
    "# scale weight of positive examples\n",
    "param['eta'] = 0.1\n",
    "param['max_depth'] = 6\n",
    "param['silent'] = 1\n",
    "param['nthread'] = 10\n",
    "param['num_class'] = 8\n",
    "\n",
    "watchlist = [ (xg_train,'train'), (xg_test, 'test') ]\n",
    "num_round = 96\n",
    "bst = xgb.train(param, xg_train, num_round, watchlist );\n",
    "# get prediction\n",
    "pred = bst.predict( xg_test )\n",
    "\n",
    "\n",
    "print ('predicting, classification error=%f' % (sum( int(pred[i]) != y_val[i] for i in range(len(y_val))) / float(len(y_val)) ))\n",
    "\n",
    "# do the same thing again, but output probabilities\n",
    "param['objective'] = 'multi:softprob'\n",
    "bst = xgb.train(param, xg_train, num_round, watchlist );\n",
    "# Note: this convention has been changed since xgboost-unity\n",
    "# get prediction, this is in 1D array, need reshape to (ndata, nclass)\n",
    "yprob = bst.predict( xg_test ).reshape( y_val.shape[0], 8 )\n",
    "ylabel = np.argmax(yprob, axis=1)\n",
    "\n",
    "print ('predicting, classification error=%f' % (sum( int(ylabel[i]) != y_val[i] for i in range(len(y_val))) / float(len(y_val)) ))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=5, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=100, n_jobs=1, oob_score=False, random_state=None,\n",
      "            verbose=0, warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=5,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "              n_estimators=100, presort='auto', random_state=None,\n",
      "              subsample=1.0, verbose=0, warm_start=False)\n",
      "RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,\n",
      "        max_iter=None, normalize=False, random_state=None, solver='auto',\n",
      "        tol=0.001)\n",
      "Train accuracy:      74.31 100.00 59.29\n",
      "Test accuracy:       45.83 49.31 42.71\n",
      "Train F1 (weighted): 72.86 100.00 57.10\n",
      "Test F1 (weighted):  42.46 49.31 40.61\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(baseline(X_train, y_train, X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 80, 1: 153, 2: 144, 3: 152, 4: 153, 5: 160, 6: 156, 7: 154})"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnnX,rnny = make_dataset(folder_path, svm=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rnnX_train = rnnX[:limit]\n",
    "rnny_train = rnny[:limit]\n",
    "rnnX_val = rnnX[limit:]\n",
    "rnny_val = rnny[limit:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({551: 1,\n",
       "         564: 1,\n",
       "         570: 2,\n",
       "         576: 9,\n",
       "         582: 5,\n",
       "         589: 13,\n",
       "         595: 8,\n",
       "         601: 17,\n",
       "         607: 26,\n",
       "         614: 20,\n",
       "         620: 29,\n",
       "         626: 19,\n",
       "         632: 24,\n",
       "         639: 34,\n",
       "         645: 38,\n",
       "         651: 56,\n",
       "         657: 57,\n",
       "         664: 54,\n",
       "         670: 56,\n",
       "         676: 52,\n",
       "         682: 54,\n",
       "         689: 46,\n",
       "         695: 45,\n",
       "         701: 60,\n",
       "         707: 43,\n",
       "         714: 38,\n",
       "         720: 37,\n",
       "         726: 32,\n",
       "         732: 25,\n",
       "         739: 20,\n",
       "         745: 27,\n",
       "         751: 18,\n",
       "         758: 19,\n",
       "         764: 14,\n",
       "         770: 22,\n",
       "         776: 19,\n",
       "         783: 12,\n",
       "         789: 13,\n",
       "         795: 11,\n",
       "         801: 10,\n",
       "         808: 10,\n",
       "         814: 6,\n",
       "         820: 8,\n",
       "         826: 8,\n",
       "         833: 2,\n",
       "         839: 5,\n",
       "         845: 1,\n",
       "         851: 2,\n",
       "         858: 1,\n",
       "         864: 5,\n",
       "         870: 4,\n",
       "         876: 1,\n",
       "         889: 3,\n",
       "         895: 3,\n",
       "         901: 1,\n",
       "         908: 1,\n",
       "         914: 1,\n",
       "         926: 1,\n",
       "         939: 1,\n",
       "         958: 1,\n",
       "         989: 1})"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter([len(x) for x in rnnX_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pad sequences (samples x time)\n",
      "x_train shape: (1152, 810, 39)\n",
      "x_test shape: (288, 810, 39)\n"
     ]
    }
   ],
   "source": [
    "'''Trains a LSTM on the IMDB sentiment classification task.\n",
    "The dataset is actually too small for LSTM to be of any advantage\n",
    "compared to simpler, much faster methods such as TF-IDF + LogReg.\n",
    "Notes:\n",
    "\n",
    "- RNNs are tricky. Choice of batch size is important,\n",
    "choice of loss and optimizer is critical, etc.\n",
    "Some configurations won't converge.\n",
    "\n",
    "- LSTM loss decrease patterns during training can be quite different\n",
    "from what you see with CNNs/MLPs/etc.\n",
    "'''\n",
    "from __future__ import print_function\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding,TimeDistributed\n",
    "from keras.layers import LSTM, GRU\n",
    "from keras.datasets import imdb\n",
    "\n",
    "max_features = 20000\n",
    "maxlen = 810  # cut texts after this number of words (among top max_features most common words)\n",
    "batch_size = 32\n",
    "\n",
    "\n",
    "y_train = rnny_train\n",
    "y_test = rnny_val\n",
    "print('Pad sequences (samples x time)')\n",
    "x_train = sequence.pad_sequences(rnnX_train, maxlen=maxlen)\n",
    "x_test = sequence.pad_sequences(rnnX_val, maxlen=maxlen)\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('x_test shape:', x_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/ipykernel/__main__.py:4: UserWarning: Update your `GRU` call to the Keras 2 API: `GRU(dropout=0.2, units=39, return_sequences=True)`\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/ipykernel/__main__.py:5: UserWarning: Update your `GRU` call to the Keras 2 API: `GRU(dropout=0.2, units=20, return_sequences=True)`\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/ipykernel/__main__.py:6: UserWarning: Update your `GRU` call to the Keras 2 API: `GRU(dropout=0.2, units=10, return_sequences=False)`\n"
     ]
    }
   ],
   "source": [
    "print('Build model...')\n",
    "model = Sequential()\n",
    "model.add(TimeDistributed(Dense(39), input_shape=(maxlen, 39)))\n",
    "model.add(GRU(output_dim=39,return_sequences=True, dropout=0.2))\n",
    "model.add(GRU(output_dim=20,return_sequences=True, dropout=0.2))\n",
    "model.add(GRU(output_dim=10,return_sequences=False, dropout=0.2))\n",
    "model.add(Dense(8, activation='softmax'))\n",
    "\n",
    "# try using different optimizers and different optimizer configs\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train...\n",
      "Train on 1152 samples, validate on 288 samples\n",
      "Epoch 1/15\n",
      "1152/1152 [==============================] - 142s - loss: 2.1030 - acc: 0.1406 - val_loss: 2.0543 - val_acc: 0.1632\n",
      "Epoch 2/15\n",
      "1152/1152 [==============================] - 166s - loss: 2.0976 - acc: 0.1415 - val_loss: 2.0316 - val_acc: 0.2014\n",
      "Epoch 3/15\n",
      "1152/1152 [==============================] - 171s - loss: 2.0558 - acc: 0.1701 - val_loss: 2.0076 - val_acc: 0.2500\n",
      "Epoch 4/15\n",
      "1152/1152 [==============================] - 173s - loss: 2.0077 - acc: 0.2005 - val_loss: 1.9720 - val_acc: 0.2083\n",
      "Epoch 5/15\n",
      "1152/1152 [==============================] - 156s - loss: 1.9790 - acc: 0.2066 - val_loss: 1.9548 - val_acc: 0.2083\n",
      "Epoch 6/15\n",
      "1152/1152 [==============================] - 157s - loss: 1.9742 - acc: 0.2014 - val_loss: 1.9267 - val_acc: 0.1910\n",
      "Epoch 7/15\n",
      "1152/1152 [==============================] - 152s - loss: 1.9687 - acc: 0.2127 - val_loss: 1.9262 - val_acc: 0.2257\n",
      "Epoch 8/15\n",
      "1152/1152 [==============================] - 132s - loss: 1.9456 - acc: 0.2318 - val_loss: 1.8961 - val_acc: 0.2326\n",
      "Epoch 9/15\n",
      "1152/1152 [==============================] - 126s - loss: 1.9291 - acc: 0.2431 - val_loss: 1.8892 - val_acc: 0.2049\n",
      "Epoch 10/15\n",
      "1152/1152 [==============================] - 126s - loss: 1.9225 - acc: 0.2543 - val_loss: 1.8803 - val_acc: 0.2431\n",
      "Epoch 11/15\n",
      "1152/1152 [==============================] - 127s - loss: 1.9126 - acc: 0.2587 - val_loss: 1.8671 - val_acc: 0.2257\n",
      "Epoch 12/15\n",
      "1152/1152 [==============================] - 127s - loss: 1.9101 - acc: 0.2500 - val_loss: 1.8911 - val_acc: 0.2153\n",
      "Epoch 13/15\n",
      "1152/1152 [==============================] - 126s - loss: 1.9004 - acc: 0.2431 - val_loss: 1.8572 - val_acc: 0.2431\n",
      "Epoch 14/15\n",
      "1152/1152 [==============================] - 128s - loss: 1.9044 - acc: 0.2474 - val_loss: 1.8573 - val_acc: 0.2569\n",
      "Epoch 15/15\n",
      "1152/1152 [==============================] - 127s - loss: 1.8965 - acc: 0.2500 - val_loss: 1.8862 - val_acc: 0.2465\n",
      "288/288 [==============================] - 6s     \n",
      "Test score: 1.88621328937\n",
      "Test accuracy: 0.246527777778\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('Train...')\n",
    "model.fit(x_train, rnny_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=15,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))\n",
    "score, acc = model.evaluate(x_test, y_test,\n",
    "                            batch_size=batch_size)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
